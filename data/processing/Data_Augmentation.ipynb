{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1917380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== IMPORTS ==========\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import tldextract\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import wordnet, stopwords\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "461b43ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# ========== INITIALIZATION ==========\n",
    "\n",
    "nltk.download('punkt', download_dir='nltk_data')\n",
    "nltk.download('punkt_tab', download_dir='nltk_data')\n",
    "nltk.download('wordnet', download_dir='nltk_data')\n",
    "nltk.download('omw-1.4', download_dir='nltk_data')\n",
    "nltk.download('stopwords', download_dir='nltk_data')\n",
    "nltk.data.path.append('./nltk_data')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d901b7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>body</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Never agree to be a loser</td>\n",
       "      <td>Buck up, your troubles caused by small dimensi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Befriend Jenna Jameson</td>\n",
       "      <td>\\nUpgrade your sex and pleasures with these te...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CNN.com Daily Top 10</td>\n",
       "      <td>&gt;+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Re: svn commit: r619753 - in /spamassassin/tru...</td>\n",
       "      <td>Would anyone object to removing .so from this ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SpecialPricesPharmMoreinfo</td>\n",
       "      <td>\\nWelcomeFastShippingCustomerSupport\\nhttp://7...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             subject  \\\n",
       "0                          Never agree to be a loser   \n",
       "1                             Befriend Jenna Jameson   \n",
       "2                               CNN.com Daily Top 10   \n",
       "3  Re: svn commit: r619753 - in /spamassassin/tru...   \n",
       "4                         SpecialPricesPharmMoreinfo   \n",
       "\n",
       "                                                body  label  \n",
       "0  Buck up, your troubles caused by small dimensi...      1  \n",
       "1  \\nUpgrade your sex and pleasures with these te...      1  \n",
       "2  >+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+...      1  \n",
       "3  Would anyone object to removing .so from this ...      0  \n",
       "4  \\nWelcomeFastShippingCustomerSupport\\nhttp://7...      1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ========== READ DATA ==========\n",
    "\n",
    "df = pd.read_csv('emails.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30ff72ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== CONSTANTS ==========\n",
    "\n",
    "URL_PATTERN = r'https?:\\/\\/[^\\s<>\"]+|www\\.[^\\s<>\"]+'\n",
    "\n",
    "GENERAL_REDIRECTS = {\n",
    "    'bit.ly', 'tinyurl.com', 'ow.ly', 'rebrand.ly', 'is.gd',\n",
    "    'buff.ly', 'adf.ly', 'shorte.st', 'cutt.ly', 'clk.im',\n",
    "    'yellkey.com', 'v.gd'\n",
    "}\n",
    "\n",
    "URGENT_KEYWORDS = {\n",
    "    'urgent', 'immediately', 'important', 'action', 'required', 'asap',\n",
    "    'alert', 'verify', 'warning', 'account', 'suspend', 'suspended',\n",
    "    'locked', 'security', 'update', 'login', 'log-in', 'expire',\n",
    "    'expiration', 'failure', 'failed', 'unauthorized', 'breach',\n",
    "    'verify', 'attention', 'risk', 'click', 'now', 'respond', 'response',\n",
    "    'confirm', 'confirmation', 'access', 'limited', 'final', 'notice',\n",
    "    'deadline', 'deactivation', 'reactivate', 'validate', 'critical',\n",
    "    'problem', 'issue', 'payment', 'invoice', 'bill', 'charge', 'refund',\n",
    "    'dispute', 'settlement', 'penalty', 'compliance', 'legal', 'violation'\n",
    "}\n",
    "\n",
    "STOP_WORDS = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4076896e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== METHODS ==========\n",
    "\n",
    "def extract_urls(text: str) -> list:\n",
    "    if not isinstance(text, str):\n",
    "        return []\n",
    "    return re.findall(URL_PATTERN, text)\n",
    "\n",
    "def count_urls(text: str) -> int:\n",
    "    if not isinstance(text, str):\n",
    "        return 0\n",
    "    return len(re.findall(URL_PATTERN, text))\n",
    "    \n",
    "def get_domain(url: str) -> str:\n",
    "    ext = tldextract.extract(url)\n",
    "    if ext.domain and ext.suffix:\n",
    "        return f\"{ext.domain}.{ext.suffix}\"\n",
    "    return None\n",
    "\n",
    "def count_urgent_words(text):\n",
    "    tokens = word_tokenize(str(text).lower())\n",
    "    lemmas = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    return sum(1 for word in lemmas if word in URGENT_KEYWORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7599ea95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== TOTAL URLS ==========\n",
    "\n",
    "df['num_urls'] = df.apply(\n",
    "    lambda row: count_urls(row['subject']) + count_urls(row['body']),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f6dfd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== REDIRECTS ==========\n",
    "\n",
    "df['num_redirects'] = df.apply(\n",
    "    lambda row: sum(\n",
    "        1 for url in extract_urls(str(row['subject']) + ' ' + str(row['body']))\n",
    "        if (lambda ext: f\"{ext.domain}.{ext.suffix}\")(tldextract.extract(url)) in GENERAL_REDIRECTS\n",
    "    ),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a20119f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== WORD COUNT ==========\n",
    "\n",
    "df['num_words'] = df.apply(\n",
    "    lambda row: len(str(row['body']).split()),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16161ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== NON-LATIN CHARS ==========\n",
    "\n",
    "df['num_chars_foreign'] = df.apply(\n",
    "    lambda row: sum(1 for char in str(row['body']) if not char.isascii()),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eede1426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== SPECIAL CHARS ==========\n",
    "\n",
    "df['num_chars_special'] = df.apply(\n",
    "    lambda row: sum(1 for char in str(row['body']) if not char.isalnum() and not char.isspace()),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c2a9da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== URGENCY ==========\n",
    "\n",
    "df['num_urgent_words'] = df['body'].apply(count_urgent_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07b419d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== STOPWORDS COUNT ==========\n",
    "\n",
    "df['num_stopwords'] = df['body'].apply(\n",
    "    lambda row: sum(\n",
    "        1 for word in word_tokenize(str(row).lower()) if word in STOP_WORDS\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0574d7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== NO STOPWORDS COLUMN ==========\n",
    "\n",
    "df['body_no_stopwords'] = df['body'].apply(\n",
    "    lambda row: ' '.join(\n",
    "        word for word in word_tokenize(str(row).lower())\n",
    "        if word.isalnum() and word not in STOP_WORDS\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc626209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>num_urls</th>\n",
       "      <th>num_redirects</th>\n",
       "      <th>num_words</th>\n",
       "      <th>num_chars_foreign</th>\n",
       "      <th>num_chars_special</th>\n",
       "      <th>num_urgent_words</th>\n",
       "      <th>num_stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>82138.000000</td>\n",
       "      <td>82138.000000</td>\n",
       "      <td>82138.000000</td>\n",
       "      <td>82138.000000</td>\n",
       "      <td>82138.000000</td>\n",
       "      <td>82138.000000</td>\n",
       "      <td>82138.000000</td>\n",
       "      <td>82138.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.518773</td>\n",
       "      <td>1.942073</td>\n",
       "      <td>0.002252</td>\n",
       "      <td>273.637999</td>\n",
       "      <td>1.472254</td>\n",
       "      <td>142.146059</td>\n",
       "      <td>2.640495</td>\n",
       "      <td>84.412245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.499650</td>\n",
       "      <td>13.261647</td>\n",
       "      <td>0.099219</td>\n",
       "      <td>812.450941</td>\n",
       "      <td>55.468074</td>\n",
       "      <td>1158.892219</td>\n",
       "      <td>10.225660</td>\n",
       "      <td>221.385045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>37.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>302.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>89.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3133.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>127119.000000</td>\n",
       "      <td>14154.000000</td>\n",
       "      <td>215985.000000</td>\n",
       "      <td>2301.000000</td>\n",
       "      <td>16873.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              label      num_urls  num_redirects      num_words  \\\n",
       "count  82138.000000  82138.000000   82138.000000   82138.000000   \n",
       "mean       0.518773      1.942073       0.002252     273.637999   \n",
       "std        0.499650     13.261647       0.099219     812.450941   \n",
       "min        0.000000      0.000000       0.000000       0.000000   \n",
       "25%        0.000000      0.000000       0.000000      51.000000   \n",
       "50%        1.000000      0.000000       0.000000     130.000000   \n",
       "75%        1.000000      1.000000       0.000000     302.000000   \n",
       "max        1.000000   3133.000000      14.000000  127119.000000   \n",
       "\n",
       "       num_chars_foreign  num_chars_special  num_urgent_words  num_stopwords  \n",
       "count       82138.000000       82138.000000      82138.000000   82138.000000  \n",
       "mean            1.472254         142.146059          2.640495      84.412245  \n",
       "std            55.468074        1158.892219         10.225660     221.385045  \n",
       "min             0.000000           0.000000          0.000000       0.000000  \n",
       "25%             0.000000          12.000000          0.000000      14.000000  \n",
       "50%             0.000000          39.000000          1.000000      37.000000  \n",
       "75%             0.000000         123.000000          3.000000      89.000000  \n",
       "max         14154.000000      215985.000000       2301.000000   16873.000000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3631909c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../emails_augmented.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phishing-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
